<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Algorithm Selection Guide</title>
    <link
        href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;600;700&family=Source+Sans+Pro:wght@300;400;600;700&family=Fira+Code:wght@400;500&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --primary: #1a365d;
            --secondary: #2c5282;
            --accent: #ed8936;
            --accent-light: #fbd38d;
            --bg-main: #f7fafc;
            --bg-card: #ffffff;
            --text-primary: #1a202c;
            --text-secondary: #4a5568;
            --border: #e2e8f0;
            --success: #38a169;
            --warning: #dd6b20;
            --info: #3182ce;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Source Sans Pro', sans-serif;
            background: var(--bg-main);
            color: var(--text-primary);
            line-height: 1.7;
        }

        /* Hero Section */
        .hero {
            background: linear-gradient(135deg, var(--primary) 0%, var(--secondary) 100%);
            color: white;
            padding: 80px 20px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .hero::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url("data:image/svg+xml,%3Csvg width='60' height='60' viewBox='0 0 60 60' xmlns='http://www.w3.org/2000/svg'%3E%3Cg fill='none' fill-rule='evenodd'%3E%3Cg fill='%23ffffff' fill-opacity='0.05'%3E%3Cpath d='M36 34v-4h-2v4h-4v2h4v4h2v-4h4v-2h-4zm0-30V0h-2v4h-4v2h4v4h2V6h4V4h-4zM6 34v-4H4v4H0v2h4v4h2v-4h4v-2H6zM6 4V0H4v4H0v2h4v4h2V6h4V4H6z'/%3E%3C/g%3E%3C/g%3E%3C/svg%3E");
        }

        .hero h1 {
            font-family: 'Playfair Display', serif;
            font-size: 3.5rem;
            font-weight: 700;
            margin-bottom: 20px;
            position: relative;
            z-index: 1;
        }

        .hero p {
            font-size: 1.3rem;
            font-weight: 300;
            max-width: 700px;
            margin: 0 auto;
            position: relative;
            z-index: 1;
            opacity: 0.95;
        }

        /* Navigation */
        .nav-container {
            background: var(--bg-card);
            border-bottom: 1px solid var(--border);
            padding: 20px;
            position: sticky;
            top: 0;
            z-index: 100;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
        }

        .nav-links {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 10px;
            max-width: 1200px;
            margin: 0 auto;
        }

        .nav-links a {
            color: var(--text-secondary);
            text-decoration: none;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 600;
            transition: all 0.3s ease;
            border: 1px solid transparent;
        }

        .nav-links a:hover {
            background: var(--accent-light);
            color: var(--primary);
            border-color: var(--accent);
        }

        /* Main Content */
        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 60px 20px;
        }

        /* Section Styling */
        section {
            margin-bottom: 80px;
        }

        .section-header {
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 3px solid var(--accent);
        }

        .section-number {
            background: var(--accent);
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-family: 'Playfair Display', serif;
            font-size: 1.5rem;
            font-weight: 700;
            flex-shrink: 0;
        }

        h2 {
            font-family: 'Playfair Display', serif;
            font-size: 2rem;
            color: var(--primary);
        }

        h3 {
            font-family: 'Playfair Display', serif;
            font-size: 1.5rem;
            color: var(--secondary);
            margin: 30px 0 15px;
        }

        h4 {
            font-size: 1.1rem;
            font-weight: 600;
            color: var(--text-primary);
            margin: 20px 0 10px;
        }

        p {
            margin-bottom: 15px;
            color: var(--text-secondary);
        }

        /* Cards */
        .card {
            background: var(--bg-card);
            border-radius: 12px;
            padding: 30px;
            margin-bottom: 25px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
            border: 1px solid var(--border);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .card:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.1);
        }

        .card-title {
            font-family: 'Playfair Display', serif;
            font-size: 1.4rem;
            color: var(--primary);
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .card-title .icon {
            font-size: 1.5rem;
        }

        /* Algorithm Cards */
        .algorithm-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
        }

        .algorithm-card {
            background: var(--bg-card);
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
            border: 1px solid var(--border);
            transition: all 0.3s ease;
        }

        .algorithm-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 12px 30px rgba(0, 0, 0, 0.12);
        }

        .algorithm-header {
            padding: 25px;
            color: white;
        }

        .algorithm-header.decision-tree {
            background: linear-gradient(135deg, #38a169 0%, #2f855a 100%);
        }

        .algorithm-header.random-forest {
            background: linear-gradient(135deg, #3182ce 0%, #2c5282 100%);
        }

        .algorithm-header.naive-bayes {
            background: linear-gradient(135deg, #805ad5 0%, #6b46c1 100%);
        }

        .algorithm-header.svm {
            background: linear-gradient(135deg, #dd6b20 0%, #c05621 100%);
        }

        .algorithm-header.neural-network {
            background: linear-gradient(135deg, #e53e3e 0%, #c53030 100%);
        }

        .algorithm-header h3 {
            color: white;
            margin: 0 0 10px 0;
            font-size: 1.3rem;
        }

        .algorithm-header p {
            color: rgba(255, 255, 255, 0.9);
            margin: 0;
            font-size: 0.95rem;
        }

        .algorithm-body {
            padding: 25px;
        }

        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.95rem;
        }

        th,
        td {
            padding: 14px 18px;
            text-align: left;
            border-bottom: 1px solid var(--border);
        }

        th {
            background: var(--primary);
            color: white;
            font-weight: 600;
            text-transform: uppercase;
            font-size: 0.85rem;
            letter-spacing: 0.5px;
        }

        tr:hover {
            background: #f8fafc;
        }

        td:first-child {
            font-weight: 600;
            color: var(--text-primary);
        }

        /* Badges */
        .badge {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 600;
            margin: 2px;
        }

        .badge-success {
            background: #c6f6d5;
            color: #22543d;
        }

        .badge-warning {
            background: #feebc8;
            color: #7b341e;
        }

        .badge-info {
            background: #bee3f8;
            color: #2a4365;
        }

        .badge-danger {
            background: #fed7d7;
            color: #822727;
        }

        /* Key Concept Box */
        .key-concept {
            background: linear-gradient(135deg, #ebf8ff 0%, #e6fffa 100%);
            border-left: 5px solid var(--info);
            padding: 25px 30px;
            border-radius: 0 12px 12px 0;
            margin: 25px 0;
        }

        .key-concept h4 {
            color: var(--info);
            margin-top: 0;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .key-concept p {
            color: var(--text-primary);
            margin-bottom: 0;
        }

        /* Warning Box */
        .warning-box {
            background: #fffaf0;
            border-left: 5px solid var(--warning);
            padding: 20px 25px;
            border-radius: 0 12px 12px 0;
            margin: 20px 0;
        }

        .warning-box h4 {
            color: var(--warning);
            margin-top: 0;
        }

        /* Success Box */
        .success-box {
            background: #f0fff4;
            border-left: 5px solid var(--success);
            padding: 20px 25px;
            border-radius: 0 12px 12px 0;
            margin: 20px 0;
        }

        .success-box h4 {
            color: var(--success);
            margin-top: 0;
        }

        /* Use Case Cards */
        .use-case {
            background: var(--bg-card);
            border-radius: 12px;
            padding: 30px;
            margin-bottom: 25px;
            border: 2px solid var(--border);
            position: relative;
        }

        .use-case::before {
            content: attr(data-scenario);
            position: absolute;
            top: -12px;
            left: 20px;
            background: var(--accent);
            color: white;
            padding: 4px 15px;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 600;
        }

        .use-case h4 {
            color: var(--primary);
            margin-top: 10px;
        }

        .recommended {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            background: var(--success);
            color: white;
            padding: 8px 18px;
            border-radius: 25px;
            font-weight: 600;
            margin: 15px 0;
        }

        /* Comparison Section */
        .comparison-table {
            overflow-x: auto;
        }

        .comparison-table table {
            min-width: 800px;
        }

        .check {
            color: var(--success);
            font-weight: bold;
        }

        .cross {
            color: #e53e3e;
            font-weight: bold;
        }

        .partial {
            color: var(--warning);
            font-weight: bold;
        }

        /* Code blocks */
        code {
            font-family: 'Fira Code', monospace;
            background: #edf2f7;
            padding: 3px 8px;
            border-radius: 4px;
            font-size: 0.9rem;
            color: var(--secondary);
        }

        /* Lists */
        ul,
        ol {
            margin: 15px 0 15px 25px;
            color: var(--text-secondary);
        }

        li {
            margin-bottom: 10px;
        }

        /* Footer */
        footer {
            background: var(--primary);
            color: white;
            text-align: center;
            padding: 40px 20px;
            margin-top: 60px;
        }

        footer p {
            color: rgba(255, 255, 255, 0.8);
            margin: 0;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .hero h1 {
                font-size: 2.5rem;
            }

            .hero p {
                font-size: 1.1rem;
            }

            .nav-links {
                flex-direction: column;
                align-items: stretch;
            }

            .nav-links a {
                text-align: center;
            }

            .algorithm-grid {
                grid-template-columns: 1fr;
            }

            table {
                font-size: 0.85rem;
            }

            th,
            td {
                padding: 10px 12px;
            }
        }

        /* Scroll animations */
        .fade-in {
            opacity: 0;
            transform: translateY(20px);
            transition: opacity 0.6s ease, transform 0.6s ease;
        }

        .fade-in.visible {
            opacity: 1;
            transform: translateY(0);
        }

        /* Flowchart styling */
        .flowchart {
            background: #f8fafc;
            border-radius: 12px;
            padding: 30px;
            margin: 25px 0;
            text-align: center;
        }

        .flow-item {
            display: inline-block;
            background: white;
            border: 2px solid var(--border);
            border-radius: 8px;
            padding: 15px 25px;
            margin: 10px;
            font-weight: 600;
        }

        .flow-item.question {
            background: var(--accent-light);
            border-color: var(--accent);
        }

        .flow-item.answer {
            background: #c6f6d5;
            border-color: var(--success);
        }

        .flow-arrow {
            display: inline-block;
            color: var(--text-secondary);
            font-size: 1.5rem;
            margin: 0 10px;
        }
    </style>
</head>

<body>
    <!-- Hero Section -->
    <header class="hero">
        <h1>Machine Learning Algorithm Selection Guide</h1>
        <p>A comprehensive guide to understanding and choosing the right algorithm for your machine learning tasks</p>
    </header>

    <!-- Navigation -->
    <nav class="nav-container">
        <div class="nav-links">
            <a href="#fundamentals">Fundamentals</a>
            <a href="#algorithms">Algorithms</a>
            <a href="#use-cases">Use Cases</a>
            <a href="#comparison">Comparison</a>
            <a href="#neural-networks">Neural Networks</a>
            <a href="#learning-types">Learning Types</a>
            <a href="#selection-guide">Selection Guide</a>
        </div>
    </nav>

    <main class="container">
        <!-- Section 1: Fundamentals -->
        <section id="fundamentals" class="fade-in">
            <div class="section-header">
                <span class="section-number">1</span>
                <h2>Fundamental Concepts</h2>
            </div>

            <div class="card">
                <h3 class="card-title"><span class="icon">üìä</span> Variance in Algorithm Selection</h3>
                <p>In machine learning, <strong>variance</strong> refers to <em>the spread of an algorithm's
                        predictions</em> ‚Äî how much the model's outputs would change if trained on different subsets of
                    data.</p>

                <table>
                    <tr>
                        <th>Concept</th>
                        <th>Definition</th>
                        <th>Implication</th>
                    </tr>
                    <tr>
                        <td>High Variance</td>
                        <td>Model predictions vary widely with different training data</td>
                        <td>Often indicates overfitting ‚Äî model is too sensitive to training data</td>
                    </tr>
                    <tr>
                        <td>Low Variance</td>
                        <td>Model predictions remain stable across different data samples</td>
                        <td>More generalizable but may underfit complex patterns</td>
                    </tr>
                </table>

                <div class="key-concept">
                    <h4>üí° The Bias-Variance Tradeoff</h4>
                    <p><strong>Bias</strong> refers to errors from overly simplistic assumptions, while
                        <strong>variance</strong> refers to sensitivity to training data fluctuations. The goal is to
                        find the sweet spot where both are minimized for optimal model performance.</p>
                </div>
            </div>

            <div class="card">
                <h3 class="card-title"><span class="icon">üîç</span> Interpretability vs. Complexity</h3>
                <p>Complex algorithms can be less desirable because they can be <strong>difficult to interpret</strong>.
                    This creates a fundamental trade-off in algorithm selection.</p>

                <table>
                    <tr>
                        <th>Aspect</th>
                        <th>Complex Algorithms</th>
                        <th>Simple Algorithms</th>
                    </tr>
                    <tr>
                        <td>Accuracy</td>
                        <td>Often higher on complex data</td>
                        <td>May be slightly lower</td>
                    </tr>
                    <tr>
                        <td>Interpretability</td>
                        <td>"Black box" ‚Äî hard to explain</td>
                        <td>Transparent and explainable</td>
                    </tr>
                    <tr>
                        <td>Stakeholder Trust</td>
                        <td>Difficult to justify decisions</td>
                        <td>Easy to communicate reasoning</td>
                    </tr>
                </table>

                <div class="warning-box">
                    <h4>‚ö†Ô∏è When Interpretability is Critical</h4>
                    <p><strong>Healthcare:</strong> Doctors need to understand why a model recommends a diagnosis<br>
                        <strong>Finance:</strong> Regulators may require explanations for credit or loan decisions<br>
                        <strong>Legal:</strong> Decisions affecting people's lives often need justification
                    </p>
                </div>
            </div>

            <div class="card">
                <h3 class="card-title"><span class="icon">‚ö°</span> Algorithm Stability</h3>
                <p><strong>Decision Trees</strong> are the most prone to instability with changing data. Small changes
                    in training data can produce dramatically different tree structures due to:</p>
                <ul>
                    <li><strong>Greedy, hierarchical splitting:</strong> Each decision depends on previous ones</li>
                    <li><strong>Cascading effects:</strong> A change at the root propagates through the entire tree</li>
                    <li><strong>High variance behavior:</strong> Very sensitive to specific training examples</li>
                </ul>

                <div class="success-box">
                    <h4>‚úÖ Random Forests: The Stability Solution</h4>
                    <p>Random Forests were invented specifically to fix decision tree instability. By averaging
                        predictions from hundreds of trees trained on different data samples, individual tree
                        instabilities cancel out.</p>
                </div>
            </div>
        </section>

        <!-- Section 2: Algorithm Deep Dives -->
        <section id="algorithms" class="fade-in">
            <div class="section-header">
                <span class="section-number">2</span>
                <h2>Algorithm Deep Dives</h2>
            </div>

            <div class="algorithm-grid">
                <!-- Decision Trees -->
                <div class="algorithm-card">
                    <div class="algorithm-header decision-tree">
                        <h3>üå≥ Decision Trees</h3>
                        <p>Flowchart-like structure for classification and regression</p>
                    </div>
                    <div class="algorithm-body">
                        <h4>Strengths</h4>
                        <ul>
                            <li>Highly interpretable ‚Äî produces visual rules</li>
                            <li>Handles both categorical and numerical data</li>
                            <li>No preprocessing required</li>
                            <li>Natural feature importance</li>
                        </ul>
                        <h4>Weaknesses</h4>
                        <ul>
                            <li>Prone to overfitting</li>
                            <li>Unstable with data changes</li>
                            <li>Can create overly complex trees</li>
                        </ul>
                        <div style="margin-top: 15px;">
                            <span class="badge badge-success">High Interpretability</span>
                            <span class="badge badge-warning">Low Stability</span>
                        </div>
                    </div>
                </div>

                <!-- Random Forests -->
                <div class="algorithm-card">
                    <div class="algorithm-header random-forest">
                        <h3>üå≤ Random Forests</h3>
                        <p>Ensemble of decision trees with bootstrap aggregating</p>
                    </div>
                    <div class="algorithm-body">
                        <h4>Strengths</h4>
                        <ul>
                            <li>Robust to noise and outliers</li>
                            <li>Handles high-dimensional data</li>
                            <li>Reduces overfitting through averaging</li>
                            <li>Provides feature importance</li>
                        </ul>
                        <h4>Weaknesses</h4>
                        <ul>
                            <li>Less interpretable than single trees</li>
                            <li>Computationally expensive</li>
                            <li>Memory intensive</li>
                        </ul>
                        <div style="margin-top: 15px;">
                            <span class="badge badge-success">High Stability</span>
                            <span class="badge badge-info">Good Accuracy</span>
                        </div>
                    </div>
                </div>

                <!-- Naive Bayes -->
                <div class="algorithm-card">
                    <div class="algorithm-header naive-bayes">
                        <h3>üìà Naive Bayes</h3>
                        <p>Probabilistic classifier based on Bayes' theorem</p>
                    </div>
                    <div class="algorithm-body">
                        <h4>Strengths</h4>
                        <ul>
                            <li>Extremely fast training and prediction</li>
                            <li>Works well with small datasets</li>
                            <li>Excellent for text classification</li>
                            <li>Memory efficient</li>
                        </ul>
                        <h4>Weaknesses</h4>
                        <ul>
                            <li>Assumes feature independence</li>
                            <li>Poor with correlated features</li>
                            <li>Struggles with spatial/temporal data</li>
                        </ul>
                        <div style="margin-top: 15px;">
                            <span class="badge badge-success">Fast & Efficient</span>
                            <span class="badge badge-danger">Independence Assumption</span>
                        </div>
                    </div>
                </div>

                <!-- SVMs -->
                <div class="algorithm-card">
                    <div class="algorithm-header svm">
                        <h3>üìê Support Vector Machines</h3>
                        <p>Finds optimal hyperplanes to separate classes</p>
                    </div>
                    <div class="algorithm-body">
                        <h4>Strengths</h4>
                        <ul>
                            <li>Effective in high dimensions</li>
                            <li>Kernel trick for non-linear data</li>
                            <li>Memory efficient (uses support vectors)</li>
                            <li>Works well with clear margins</li>
                        </ul>
                        <h4>Weaknesses</h4>
                        <ul>
                            <li>Less interpretable</li>
                            <li>Slow with large datasets</li>
                            <li>Requires feature scaling</li>
                        </ul>
                        <div style="margin-top: 15px;">
                            <span class="badge badge-info">Kernel Trick</span>
                            <span class="badge badge-warning">Needs Preprocessing</span>
                        </div>
                    </div>
                </div>

                <!-- Neural Networks -->
                <div class="algorithm-card">
                    <div class="algorithm-header neural-network">
                        <h3>üß† Neural Networks</h3>
                        <p>Layered architecture mimicking brain neurons</p>
                    </div>
                    <div class="algorithm-body">
                        <h4>Strengths</h4>
                        <ul>
                            <li>State-of-the-art for images, text, speech</li>
                            <li>Automatic feature learning</li>
                            <li>Handles complex non-linear patterns</li>
                            <li>Scales with more data</li>
                        </ul>
                        <h4>Weaknesses</h4>
                        <ul>
                            <li>"Black box" ‚Äî low interpretability</li>
                            <li>High computational cost</li>
                            <li>Requires large datasets</li>
                            <li>Prone to overfitting without regularization</li>
                        </ul>
                        <div style="margin-top: 15px;">
                            <span class="badge badge-success">Highest Accuracy</span>
                            <span class="badge badge-danger">Resource Intensive</span>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Kernel Trick Deep Dive -->
            <div class="card">
                <h3 class="card-title"><span class="icon">üéØ</span> The Kernel Trick (SVMs)</h3>
                <p>The <strong>kernel trick</strong> is a signature technique that allows SVMs to handle non-linearly
                    separable data without explicitly computing transformations to higher dimensions.</p>

                <table>
                    <tr>
                        <th>Kernel Type</th>
                        <th>Best For</th>
                        <th>Characteristics</th>
                    </tr>
                    <tr>
                        <td>Linear</td>
                        <td>Already linearly separable data</td>
                        <td>Simple, fast, interpretable</td>
                    </tr>
                    <tr>
                        <td>Polynomial</td>
                        <td>Moderate non-linearity</td>
                        <td>Captures polynomial relationships</td>
                    </tr>
                    <tr>
                        <td>RBF (Radial Basis Function)</td>
                        <td>Complex, highly non-linear boundaries</td>
                        <td>Most flexible, commonly used</td>
                    </tr>
                    <tr>
                        <td>Sigmoid</td>
                        <td>Neural network-like behavior</td>
                        <td>Similar to activation functions</td>
                    </tr>
                </table>

                <div class="key-concept">
                    <h4>üí° Why It's Called a "Trick"</h4>
                    <p>The kernel trick provides the <em>benefits</em> of working in a high-dimensional space (finding
                        complex boundaries) without the <em>computational cost</em> of actually transforming and
                        operating in that space. It calculates relationships as if the data were transformed, without
                        doing the transformation.</p>
                </div>
            </div>
        </section>

        <!-- Section 3: Use Cases -->
        <section id="use-cases" class="fade-in">
            <div class="section-header">
                <span class="section-number">3</span>
                <h2>Algorithm Selection by Use Case</h2>
            </div>

            <div class="use-case" data-scenario="Business Analytics">
                <h4>Customer Churn Prediction</h4>
                <p>Detecting which customers are likely to cancel a subscription-based service.</p>
                <div class="recommended">‚úì Recommended: Decision Trees</div>
                <p><strong>Why:</strong> Business teams need to understand <em>why</em> customers churn to design
                    effective interventions. Decision trees provide clear, actionable rules like "If usage dropped >50%
                    AND tenure <6 months ‚Üí high churn risk."</p>
                        <ul>
                            <li>Interpretable segmentation enables targeted retention campaigns</li>
                            <li>Feature importance reveals key churn drivers</li>
                            <li>Handles mixed customer data (numeric + categorical)</li>
                        </ul>
            </div>

            <div class="use-case" data-scenario="NLP / Text">
                <h4>Text Classification (Speed Critical)</h4>
                <p>Classifying documents, spam filtering, sentiment analysis where efficiency matters.</p>
                <div class="recommended">‚úì Recommended: Naive Bayes</div>
                <p><strong>Why:</strong> When speed and efficiency are priorities, Naive Bayes delivers remarkably fast
                    training and prediction while still achieving solid accuracy.</p>
                <ul>
                    <li>Simply counts word frequencies ‚Äî no complex optimization</li>
                    <li>Nearly instantaneous predictions</li>
                    <li>Scales linearly with data size</li>
                    <li>Perfect for real-time applications like spam filters</li>
                </ul>
            </div>

            <div class="use-case" data-scenario="Computer Vision">
                <h4>Medical Image Classification</h4>
                <p>Detecting tumors, diagnosing conditions from X-rays, CT scans, or retinal images.</p>
                <div class="recommended">‚úì Recommended: Neural Networks (CNNs)</div>
                <p><strong>Why:</strong> When accuracy is paramount and interpretability can be traded off, neural
                    networks achieve state-of-the-art performance on image data.</p>
                <ul>
                    <li>Automatically learns hierarchical features (edges ‚Üí textures ‚Üí structures ‚Üí pathologies)</li>
                    <li>Matches or exceeds human expert performance</li>
                    <li>Transfer learning enables training with smaller medical datasets</li>
                    <li>Handles raw pixel data without manual feature engineering</li>
                </ul>
            </div>

            <div class="use-case" data-scenario="IoT / Industrial">
                <h4>Predictive Maintenance (Noisy Sensor Data)</h4>
                <p>Predicting equipment failure from sensor readings that contain noise and outliers.</p>
                <div class="recommended">‚úì Recommended: Random Forests</div>
                <p><strong>Why:</strong> The ensemble nature of Random Forests provides natural robustness against the
                    noise inherent in sensor data.</p>
                <ul>
                    <li>Averaging across trees smooths out noise impact</li>
                    <li>Outliers affect only some trees ‚Äî majority voting minimizes influence</li>
                    <li>Handles correlated sensor readings through random feature selection</li>
                    <li>Identifies which sensors are most predictive of failure</li>
                </ul>
            </div>

            <div class="use-case" data-scenario="Finance">
                <h4>Financial Forecasting</h4>
                <p>Stock price prediction, risk assessment, market analysis.</p>
                <div class="recommended">‚ö†Ô∏è Consider: Neural Networks (with caveats)</div>
                <p><strong>Main Limitation:</strong> High computational cost and resource demand</p>
                <ul>
                    <li>Requires powerful GPUs and significant infrastructure</li>
                    <li>Markets move fast ‚Äî models may need frequent retraining</li>
                    <li>Real-time predictions require low-latency systems</li>
                    <li>Lack of interpretability can be problematic for regulators</li>
                </ul>
                <div class="warning-box">
                    <h4>‚ö†Ô∏è Alternative Consideration</h4>
                    <p>Simpler models (linear regression, gradient boosting) may be preferred when interpretability and
                        regulatory compliance are required, even if they sacrifice some predictive accuracy.</p>
                </div>
            </div>

            <div class="use-case" data-scenario="Spatial Analysis">
                <h4>Spatial Data with Dependencies</h4>
                <p>Geographic data, location-based analysis, spatial patterns.</p>
                <div class="recommended">‚úó Avoid: Naive Bayes</div>
                <p><strong>Why Naive Bayes fails here:</strong> Its core <em>independence assumption</em> is
                    fundamentally violated by spatial data.</p>
                <ul>
                    <li>Spatial data has inherent dependencies ‚Äî nearby points are related (spatial autocorrelation)
                    </li>
                    <li>Temperature at one location correlates with nearby locations</li>
                    <li>When features are dependent, probability calculations become unreliable</li>
                </ul>
            </div>
        </section>

        <!-- Section 4: Algorithm Comparison -->
        <section id="comparison" class="fade-in">
            <div class="section-header">
                <span class="section-number">4</span>
                <h2>Comprehensive Algorithm Comparison</h2>
            </div>

            <div class="comparison-table">
                <table>
                    <tr>
                        <th>Algorithm</th>
                        <th>Interpretability</th>
                        <th>Speed</th>
                        <th>Handles Mixed Data</th>
                        <th>Noise Robustness</th>
                        <th>Data Requirements</th>
                    </tr>
                    <tr>
                        <td>Decision Trees</td>
                        <td><span class="check">‚úì Excellent</span></td>
                        <td><span class="check">‚úì Fast</span></td>
                        <td><span class="check">‚úì Excellent</span></td>
                        <td><span class="cross">‚úó Poor</span></td>
                        <td>Small to Medium</td>
                    </tr>
                    <tr>
                        <td>Random Forests</td>
                        <td><span class="cross">‚úó Low</span></td>
                        <td><span class="partial">‚óê Moderate</span></td>
                        <td><span class="check">‚úì Good</span></td>
                        <td><span class="check">‚úì Excellent</span></td>
                        <td>Medium to Large</td>
                    </tr>
                    <tr>
                        <td>Naive Bayes</td>
                        <td><span class="partial">‚óê Moderate</span></td>
                        <td><span class="check">‚úì Fastest</span></td>
                        <td><span class="partial">‚óê Moderate</span></td>
                        <td><span class="partial">‚óê Moderate</span></td>
                        <td>Small</td>
                    </tr>
                    <tr>
                        <td>SVMs</td>
                        <td><span class="cross">‚úó Low</span></td>
                        <td><span class="cross">‚úó Slow (large data)</span></td>
                        <td><span class="cross">‚úó Needs encoding</span></td>
                        <td><span class="check">‚úì Good</span></td>
                        <td>Medium</td>
                    </tr>
                    <tr>
                        <td>Neural Networks</td>
                        <td><span class="cross">‚úó Very Low</span></td>
                        <td><span class="cross">‚úó Slowest</span></td>
                        <td><span class="cross">‚úó Needs encoding</span></td>
                        <td><span class="partial">‚óê Varies</span></td>
                        <td>Large</td>
                    </tr>
                </table>
            </div>

            <div class="card">
                <h3 class="card-title"><span class="icon">üéØ</span> Quick Selection Guide</h3>
                <table>
                    <tr>
                        <th>If You Need...</th>
                        <th>Choose...</th>
                    </tr>
                    <tr>
                        <td>Maximum interpretability + mixed data</td>
                        <td><strong>Decision Trees</strong></td>
                    </tr>
                    <tr>
                        <td>Noise robustness + stability</td>
                        <td><strong>Random Forests</strong></td>
                    </tr>
                    <tr>
                        <td>Speed + efficiency (text classification)</td>
                        <td><strong>Naive Bayes</strong></td>
                    </tr>
                    <tr>
                        <td>Non-linear separation + high dimensions</td>
                        <td><strong>SVMs with kernel</strong></td>
                    </tr>
                    <tr>
                        <td>Maximum accuracy (images/text/speech)</td>
                        <td><strong>Neural Networks</strong></td>
                    </tr>
                </table>
            </div>
        </section>

        <!-- Section 5: Neural Networks Deep Dive -->
        <section id="neural-networks" class="fade-in">
            <div class="section-header">
                <span class="section-number">5</span>
                <h2>Neural Networks: Hidden Layers & Architecture</h2>
            </div>

            <div class="card">
                <h3 class="card-title"><span class="icon">üß†</span> The Role of Hidden Layers</h3>
                <p>The primary role of hidden layers is to <strong>create non-linear transformations of the input
                        data</strong>. They are the "deep" in deep learning ‚Äî where networks learn to transform raw
                    inputs into increasingly useful representations.</p>

                <h4>What Hidden Layers Do:</h4>
                <ol>
                    <li><strong>Compute weighted sums</strong> of inputs from the previous layer</li>
                    <li><strong>Apply activation functions</strong> (ReLU, sigmoid, tanh) to introduce non-linearity
                    </li>
                    <li><strong>Build hierarchical features</strong> ‚Äî each layer learns more abstract representations
                    </li>
                </ol>

                <table>
                    <tr>
                        <th>Layer Depth</th>
                        <th>What It Learns (Image Example)</th>
                    </tr>
                    <tr>
                        <td>Early Layers</td>
                        <td>Edges, basic shapes, simple textures</td>
                    </tr>
                    <tr>
                        <td>Middle Layers</td>
                        <td>Patterns, object parts, complex textures</td>
                    </tr>
                    <tr>
                        <td>Deep Layers</td>
                        <td>Objects, faces, high-level concepts</td>
                    </tr>
                </table>

                <div class="key-concept">
                    <h4>üí° Why Non-Linearity is Essential</h4>
                    <p>Without non-linear activation functions, stacking multiple layers would be mathematically
                        pointless ‚Äî any number of linear transformations collapse into a single linear transformation.
                        Non-linearity is what enables neural networks to approximate <em>any</em> complex function.</p>
                </div>
            </div>
        </section>

        <!-- Section 6: Learning Types -->
        <section id="learning-types" class="fade-in">
            <div class="section-header">
                <span class="section-number">6</span>
                <h2>Supervised vs. Unsupervised Learning</h2>
            </div>

            <div class="card">
                <table>
                    <tr>
                        <th>Aspect</th>
                        <th>Supervised Learning</th>
                        <th>Unsupervised Learning</th>
                    </tr>
                    <tr>
                        <td>Data</td>
                        <td>Labeled (inputs + correct answers)</td>
                        <td>Unlabeled (inputs only)</td>
                    </tr>
                    <tr>
                        <td>Goal</td>
                        <td>Predict known outcomes</td>
                        <td>Discover hidden patterns</td>
                    </tr>
                    <tr>
                        <td>Examples</td>
                        <td>Classification, Regression</td>
                        <td>Clustering, Dimensionality Reduction</td>
                    </tr>
                </table>

                <h4>Example Tasks:</h4>
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 20px;">
                    <div>
                        <h4 style="color: var(--info);">Supervised Tasks</h4>
                        <ul>
                            <li>Predicting loan defaults</li>
                            <li>Forecasting sales figures</li>
                            <li>Diagnosing medical conditions</li>
                            <li>Spam detection</li>
                        </ul>
                    </div>
                    <div>
                        <h4 style="color: var(--success);">Unsupervised Tasks</h4>
                        <ul>
                            <li>Customer segmentation</li>
                            <li>Anomaly detection</li>
                            <li>Topic modeling</li>
                            <li>Feature compression</li>
                        </ul>
                    </div>
                </div>

                <div class="key-concept">
                    <h4>üí° The Key Distinction</h4>
                    <p>If you're asking the model to <em>predict</em> a known outcome, it's supervised. If you're asking
                        it to <em>discover</em> structure you don't already know, it's unsupervised.</p>
                </div>
            </div>
        </section>

        <!-- Section 7: Selection Guide -->
        <section id="selection-guide" class="fade-in">
            <div class="section-header">
                <span class="section-number">7</span>
                <h2>When to Choose Simpler Algorithms</h2>
            </div>

            <div class="card">
                <p>Several factors might lead you to select a <strong>simpler algorithm</strong> over a more complex
                    one:</p>

                <table>
                    <tr>
                        <th>Factor</th>
                        <th>Favors Simple</th>
                        <th>Favors Complex</th>
                    </tr>
                    <tr>
                        <td>Explainability</td>
                        <td><span class="check">‚úì Critical requirement</span></td>
                        <td>Not needed</td>
                    </tr>
                    <tr>
                        <td>Data Size</td>
                        <td>Small datasets</td>
                        <td><span class="check">‚úì Large datasets</span></td>
                    </tr>
                    <tr>
                        <td>Relationships</td>
                        <td>Linear/simple patterns</td>
                        <td><span class="check">‚úì Complex non-linear</span></td>
                    </tr>
                    <tr>
                        <td>Resources</td>
                        <td>Limited compute</td>
                        <td><span class="check">‚úì GPU clusters available</span></td>
                    </tr>
                    <tr>
                        <td>Accuracy Need</td>
                        <td>"Good enough" acceptable</td>
                        <td><span class="check">‚úì Maximum accuracy required</span></td>
                    </tr>
                </table>

                <div class="success-box">
                    <h4>‚úÖ The Practical Wisdom</h4>
                    <p>A model that stakeholders can <em>trust and act upon</em> often delivers more real-world value
                        than a slightly more accurate black box. Start simple, and only add complexity when it provides
                        measurable improvement that justifies the trade-offs.</p>
                </div>
            </div>

            <div class="flowchart">
                <h4 style="margin-bottom: 20px;">Decision Framework</h4>
                <div class="flow-item question">Need to explain decisions?</div>
                <span class="flow-arrow">‚Üí</span>
                <div class="flow-item answer">Yes: Decision Trees / Logistic Regression</div>
                <br><br>
                <div class="flow-item question">Speed critical?</div>
                <span class="flow-arrow">‚Üí</span>
                <div class="flow-item answer">Yes: Naive Bayes</div>
                <br><br>
                <div class="flow-item question">Noisy/unstable data?</div>
                <span class="flow-arrow">‚Üí</span>
                <div class="flow-item answer">Yes: Random Forests</div>
                <br><br>
                <div class="flow-item question">Complex patterns + large data?</div>
                <span class="flow-arrow">‚Üí</span>
                <div class="flow-item answer">Yes: Neural Networks</div>
            </div>
        </section>

        <!-- Summary Card -->
        <section class="fade-in">
            <div class="card"
                style="background: linear-gradient(135deg, var(--primary) 0%, var(--secondary) 100%); color: white;">
                <h3 style="color: white; font-size: 1.6rem; margin-bottom: 20px;">üìö Key Takeaways</h3>
                <ol style="color: rgba(255,255,255,0.95);">
                    <li style="margin-bottom: 15px;"><strong>Variance</strong> measures prediction spread ‚Äî high
                        variance means the model is sensitive to training data changes.</li>
                    <li style="margin-bottom: 15px;"><strong>Decision Trees</strong> offer maximum interpretability but
                        are unstable; <strong>Random Forests</strong> fix this through ensemble averaging.</li>
                    <li style="margin-bottom: 15px;"><strong>Naive Bayes</strong> is fastest for text but fails with
                        dependent features (like spatial data).</li>
                    <li style="margin-bottom: 15px;"><strong>SVMs</strong> use the kernel trick to handle non-linear
                        data without explicit transformation.</li>
                    <li style="margin-bottom: 15px;"><strong>Neural Networks</strong> achieve highest accuracy for
                        complex data but require significant resources and sacrifice interpretability.</li>
                    <li style="margin-bottom: 15px;">Choose <strong>simpler algorithms</strong> when explainability is
                        required ‚Äî this is often more valuable than marginal accuracy gains.</li>
                    <li><strong>Hidden layers</strong> create non-linear transformations, enabling networks to learn
                        hierarchical features.</li>
                </ol>
            </div>
        </section>
    </main>

    <footer>
        <p>Machine Learning Algorithm Selection Guide | Comprehensive Learning Resource</p>
        <p style="margin-top: 10px; font-size: 0.9rem;">Created for understanding algorithm trade-offs and selection
            criteria</p>
    </footer>

    <script>
        // Scroll animation
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        }, observerOptions);

        document.querySelectorAll('.fade-in').forEach(el => observer.observe(el));

        // Smooth scroll for navigation
        document.querySelectorAll('.nav-links a').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                target.scrollIntoView({ behavior: 'smooth', block: 'start' });
            });
        });
    </script>
</body>

</html>